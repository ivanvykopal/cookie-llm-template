model:
    name: meta-llama/Llama-3.1-8B-Instruct
    quantization: False
    max_tokens: 1024
    do_sample: False
    temperature: 0.7
    system_prompt: "You are a helpful assistant."
prompt:
    prompt_type: prompt
    template: "{prompt}"